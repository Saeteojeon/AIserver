{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Those are excellent choices! Each of these neighborhoods in Seoul offers a unique experience and caters to different preferences.\n",
      "\n",
      "- Gangnam: Known for its upscale shopping, dining, and entertainment options, Gangnam is a vibrant and bustling neighborhood with a mix of modern and traditional elements.\n",
      "\n",
      "- Hongdae: Popular among young people and artists, Hongdae is a trendy neighborhood known for its indie music scene, street performances, and vibrant nightlife.\n",
      "\n",
      "- Itaewon: A diverse and multicultural neighborhood, Itaewon is famous for its international cuisine, trendy boutiques, and vibrant nightlife. It's a great place to experience a mix of cultures.\n",
      "\n",
      "- Insadong: If you're interested in traditional Korean culture, Insadong is the place to be. This neighborhood is known for its traditional tea houses, art galleries, and antique shops, offering a glimpse into Korea's rich cultural heritage.\n",
      "\n",
      "Depending on your preferences and interests, any of these neighborhoods could be a great choice for you to explore and experience different aspects of Seoul's vibrant city life.\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# Initialize the memory\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human. You have to recommend suitable neighborhoods when human ask you questions.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the LLMChain\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define a function to load memory\n",
    "def load_memory(_):\n",
    "    memory_variables = memory.load_memory_variables({})\n",
    "    return memory_variables.get(\"chat_history\", [])\n",
    "\n",
    "# Define the runnable chain with memory assignment\n",
    "chain_with_memory = RunnablePassthrough.assign(chat_history=load_memory) | prompt | llm\n",
    "\n",
    "# Define a function to invoke the chain and save context\n",
    "def invoke_chain(question):\n",
    "    result = chain_with_memory.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    return result.content\n",
    "\n",
    "# Function to recommend a neighborhood based on input city\n",
    "\n",
    "\n",
    "# Example usage of the chain and neighborhood recommendation\n",
    "invoke_chain(\"My name is Nico\")\n",
    "invoke_chain(\"I live in Seoul\")\n",
    "response = invoke_chain(\"Can you recommend a neighborhood?\")\n",
    "\n",
    "\n",
    "\n",
    "# Additional invocation to integrate the recommendation into the conversation\n",
    "final_response = invoke_chain(f\"Recommended neighborhoods in {city} are {', '.join(neighborhoods)}.\")\n",
    "print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dream\\OneDrive\\FULLSTACK-GPT\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\dream\\OneDrive\\FULLSTACK-GPT\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.1)\n",
    "\n",
    "# Initialize the memory\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human. You have to recommend suitable neighborhoods when human ask you questions. I recommend a neighborhood, but for example, you have to tell me the details of the neighborhood unit like Sangsu-dong, Mapo-gu.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the LLMChain\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define a function to load memory\n",
    "def load_memory(input):\n",
    "    print(input)\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "    \n",
    "# Define the runnable chain with memory assignment  \n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "# Define a function to invoke the chain and save context\n",
    "def invoke_chain(question):\n",
    "    \n",
    "    result=chain.invoke(\n",
    "        {\n",
    "        \"question\": question\n",
    "        }\n",
    "    )\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dream\\OneDrive\\FULLSTACK-GPT\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\dream\\OneDrive\\FULLSTACK-GPT\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.1)\n",
    "\n",
    "# Initialize the memory\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human. You have to recommend suitable neighborhoods when human ask you questions.When you recommend a neighborhood, rather than explaining it, recommend several neighborhoods and let me know the dong or eup units.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the LLMChain\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define a function to load memory\n",
    "def load_memory(input):\n",
    "    print(input)\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "    \n",
    "# Define the runnable chain with memory assignment  \n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "# Define a function to invoke the chain and save context\n",
    "def invoke_chain(question):\n",
    "    \n",
    "    result=chain.invoke(\n",
    "        {\n",
    "        \"question\": question\n",
    "        }\n",
    "    )\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Hello, my name is Seok Mun.'}\n",
      "content='Hello Seok Mun! How can I assist you today? Are you looking for recommendations on neighborhoods?' response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 65, 'total_tokens': 85}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_294de9593d', 'finish_reason': 'stop', 'logprobs': None} id='run-e963032a-8c11-4ae4-8114-94ed0d795335-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Hello, my name is Seok Mun.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'yes. Please recommend a neighborhood where the subway is 5 minutes away'}\n",
      "content='Certainly! Here are a few neighborhoods where you can find a subway station within a 5-minute walk:\\n\\n1. Gangnam-gu: Yeoksam-dong, Daechi-dong\\n2. Mapo-gu: Sangam-dong, Dohwa-dong\\n3. Jongno-gu: Gwanghwamun-dong, Sajik-dong\\n\\nThese areas are well-connected by public transport, especially the subway, making commuting quite convenient.' response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 107, 'total_tokens': 204}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_294de9593d', 'finish_reason': 'stop', 'logprobs': None} id='run-8638bfaf-f5ad-4016-ad57-756a4d8d77ea-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"yes. Please recommend a neighborhood where the subway is 5 minutes away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Which neighborhood is close to the hospital?.'}\n",
      "content='Here are some neighborhoods that are close to major hospitals:\\n\\n1. Jongno-gu: Hyoja-dong (near Seoul National University Hospital)\\n2. Seodaemun-gu: Yeonhui-dong (near Severance Hospital)\\n3. Gangnam-gu: Samseong-dong (near Samsung Medical Center)\\n\\nThese areas have good access to healthcare facilities.' response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 208, 'total_tokens': 286}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_294de9593d', 'finish_reason': 'stop', 'logprobs': None} id='run-32dd437d-d3bd-434d-a1a8-cfbb6c4daad5-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Which neighborhood is close to the hospital?.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Where is cgv close?'}\n",
      "content='Here are some neighborhoods with close proximity to CGV cinemas:\\n\\n1. Yongsan-gu: Hangangno-dong (near CGV Yongsan)\\n2. Mapo-gu: Seogyo-dong (near CGV Hongdae)\\n3. Gangnam-gu: Yeoksam-dong (near CGV Gangnam)\\n\\nThese areas are popular for their entertainment options, including movie theaters.' response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 244, 'total_tokens': 328}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_e9446dc58f', 'finish_reason': 'stop', 'logprobs': None} id='run-75a12e1f-1058-4e77-8054-691405bc17e7-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Where is cgv close?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'I want a quiet atmosphere. Where is a quiet neighborhood?'}\n",
      "content='For a quiet atmosphere, consider these neighborhoods:\\n\\n1. Seongbuk-gu: Seongbuk-dong\\n2. Jongno-gu: Buam-dong\\n3. Gangnam-gu: Suseo-dong\\n\\nThese areas are known for their more tranquil environment, making them ideal for those seeking peace and quiet.' response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 323, 'total_tokens': 393}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_0737e0dfd9', 'finish_reason': 'stop', 'logprobs': None} id='run-c08f814b-b4d8-464c-9216-ff0f937ff5f0-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"I want a quiet atmosphere. Where is a quiet neighborhood?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'I want to buy a monthly rent, where is the lowest monthly rent?'}\n",
      "content='For areas with generally lower monthly rents, consider these neighborhoods:\\n\\n1. Dobong-gu: Banghak-dong\\n2. Geumcheon-gu: Doksan-dong\\n3. Gwanak-gu: Sillim-dong\\n\\nThese areas are known for more affordable housing options, which might be suitable for finding lower monthly rents.' response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 397, 'total_tokens': 469}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_294de9593d', 'finish_reason': 'stop', 'logprobs': None} id='run-61cc9937-212e-4b74-a69f-eddfa62d368a-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"I want to buy a monthly rent, where is the lowest monthly rent?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Where are there many cafes and convenience stores nearby?'}\n",
      "content='For neighborhoods with a high density of cafes and convenience stores, consider these areas:\\n\\n1. Mapo-gu: Hongdae (Hongik University area)\\n2. Jongno-gu: Insadong\\n3. Gangnam-gu: Garosu-gil (Sinsa-dong)\\n\\nThese areas are bustling with numerous cafes and convenience stores, making them very convenient for residents and visitors alike.' response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 453, 'total_tokens': 535}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_294de9593d', 'finish_reason': 'stop', 'logprobs': None} id='run-9040a6a4-4d8e-4a58-9e3b-557ee8d59c4c-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Where are there many cafes and convenience stores nearby?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': \"What's the best neighborhood you've organized so far?\"}\n",
      "content=\"It depends on what you're looking for in a neighborhood. Here are some top picks based on different criteria:\\n\\n1. **For Public Transport Accessibility**: Gangnam-gu (Gangnam-daero, Yeoksam-dong)\\n2. **For Healthcare Access**: Jongno-gu (Hyoja-dong near Seoul National University Hospital)\\n3. **For Entertainment and Lifestyle (Cafes and Convenience Stores)**: Mapo-gu (Hongdae, Hongik University area)\\n\\nEach of these neighborhoods excels in its respective category, offering convenience and quality of life based on your specific needs.\" response_metadata={'token_usage': {'completion_tokens': 122, 'prompt_tokens': 518, 'total_tokens': 640}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_294de9593d', 'finish_reason': 'stop', 'logprobs': None} id='run-0a731c93-cd1e-480c-894d-2b2c3f34cb3e-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What's the best neighborhood you've organized so far?\")\n",
    "invoke_chain(\"Please recommend one of the most optimized neighborhoods based on the current conditions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\dream\\onedrive\\fullstack-gpt\\env\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\dream\\onedrive\\fullstack-gpt\\env\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\dream\\onedrive\\fullstack-gpt\\env\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\dream\\onedrive\\fullstack-gpt\\env\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\dream\\onedrive\\fullstack-gpt\\env\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\dream\\onedrive\\fullstack-gpt\\env\\lib\\site-packages (from flask) (1.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dream\\onedrive\\fullstack-gpt\\env\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dream\\onedrive\\fullstack-gpt\\env\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html lang=en>\n",
      "<title>500 Internal Server Error</title>\n",
      "<h1>Internal Server Error</h1>\n",
      "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'http://127.0.0.1:5000/invoke_chain'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data = {\n",
    "    \"question\": \"추천할 만한 동네를 알려줘\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/invoke_chain', methods=['POST'])\n",
    "def invoke_chain_endpoint():\n",
    "    data = request.get_json()\n",
    "    question = data.get(\"question\")\n",
    "    if not question:\n",
    "        return jsonify({\"error\": \"No question provided\"}), 400\n",
    "    \n",
    "    result = invoke_chain(question)\n",
    "    return jsonify({\"response\": result})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
